{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cl3cfQa7qdSR"
   },
   "source": [
    "# Sentiment classification\n",
    "\n",
    " * How to perform text classification using Scikit-learn, specifically sentiment classification\n",
    " * Apply a Naive Bayes and Logistic Regression classifiers\n",
    " * How to evaluate a classifier with key metrics including Precision, Recall, F1, and confusion matrix\n",
    " * How to use FeatureUnion and Pipelines to incorporate multiple features\n",
    " * How to incorporate different types of features (sparse and dense)\n",
    " * How to use GridSearchCV to tune parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9eLqycD_5dF"
   },
   "source": [
    "Our dataset this week comes from reviews for Android apps on the Play Store. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "ArN6SGUFqlWI",
    "outputId": "832a91b7-236f-4039-dbbf-9af225be27e6"
   },
   "outputs": [],
   "source": [
    "local_file = \"reviews_Apps_for_Android_5.json.gz\"\n",
    "#!curl -o  $local_file https://storage.googleapis.com/tad2018/reviews_Apps_for_Android_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2zZjyjvM_AFh"
   },
   "source": [
    "We will limit the number of reviews to make it smaller so that the lab is faster to complete. You may remove the limit if you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fMfcZ4nFq-Zn",
    "outputId": "7a97559b-5147-426b-8af5-ea1e260ce497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 752937 reviews in our dataset\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "review_list = list()\n",
    "\n",
    "# Construct a dataframe, by opening the JSON file line-by-line\n",
    "with gzip.open(local_file) as jsonfile:\n",
    "    for i, line in enumerate(jsonfile):\n",
    "        review = json.loads(line)\n",
    "    #print(review)\n",
    "    #if (i >= review_limit): break\n",
    "    # asin is the product number, overall is the number of stars awarded by the user for that product\n",
    "        review_list.append( (review['asin'], review['reviewerID'], review['reviewText'], review['summary'], review['overall']))\n",
    "                   \n",
    "print(\"We have %d reviews in our dataset\"  % len(review_list))\n",
    "\n",
    "collabels = ['productId', 'reviewerID', 'reviewText', 'summary', 'overall']\n",
    "reviews = pd.DataFrame(review_list, columns=collabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16Uoo02mDV-a"
   },
   "source": [
    "Let's explore the data before we jump into classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "colab_type": "code",
    "id": "4YwRH2wXD5eP",
    "outputId": "954dcb33-4aca-4205-e605-1af8ba547097"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A1N4O8VOJZTDVB</td>\n",
       "      <td>Loves the song, so he really couldn't wait to ...</td>\n",
       "      <td>Really cute</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A2HQWU6HUKIEC7</td>\n",
       "      <td>Oh, how my little grandson loves this app. He'...</td>\n",
       "      <td>2-year-old loves it</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A1SXASF6GYG96I</td>\n",
       "      <td>I found this at a perfect time since my daught...</td>\n",
       "      <td>Fun game</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A2B54P9ZDYH167</td>\n",
       "      <td>My 1 year old goes back to this game over and ...</td>\n",
       "      <td>We love our Monkeys!</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>AFOFZDTX5UC6D</td>\n",
       "      <td>There are three different versions of the song...</td>\n",
       "      <td>This is my granddaughters favorite app on my K...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A331GYAT4ESYI3</td>\n",
       "      <td>THis is just so cute and a great app for littl...</td>\n",
       "      <td>so cute</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A2YEHF8T823TDC</td>\n",
       "      <td>I watch my great grandson 4 days a week and it...</td>\n",
       "      <td>Terrific!</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A3699WHISXX94Z</td>\n",
       "      <td>This app is wild and crazy.  Little ones love ...</td>\n",
       "      <td>Five Little Monkeys</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A2BXV49EIES2TB</td>\n",
       "      <td>love love love this app. I was going through d...</td>\n",
       "      <td>love but to quite</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A37HM5TMCMHJES</td>\n",
       "      <td>Very cute, with alot of items to move about.  ...</td>\n",
       "      <td>Cute</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A1FYZPJLU78R2Y</td>\n",
       "      <td>WELL THE CHILDREN LOVE IT AFTER AWHILE YOU GET...</td>\n",
       "      <td>MONKEYS</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>AV58L39SOERMI</td>\n",
       "      <td>I got this app because my 2 year old daughter ...</td>\n",
       "      <td>Could be better....</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A31XG60B64OW74</td>\n",
       "      <td>My three year old Plays this game the most he ...</td>\n",
       "      <td>Five little monkeys</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A39JZ61LPIVY91</td>\n",
       "      <td>Good for little ones, especially if  know the ...</td>\n",
       "      <td>Good for small children</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>AIRKROQMCBVG4</td>\n",
       "      <td>My two year old grandson loves this game and p...</td>\n",
       "      <td>Fun, fun, fun !!</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>AELVL0VXR3VFN</td>\n",
       "      <td>My granddaughter really loves this. She will l...</td>\n",
       "      <td>So cute</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>A55641MA1CS5F</td>\n",
       "      <td>love it, but wish it was fullscreen on honeyco...</td>\n",
       "      <td>love it</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B004AFQAUA</td>\n",
       "      <td>A39TLD5D8M76M4</td>\n",
       "      <td>does not let you sample only for a sec. if you...</td>\n",
       "      <td>dont play there</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B004AFQAUA</td>\n",
       "      <td>A2XJJKZSEYYW8T</td>\n",
       "      <td>this is a very good app and it you need this s...</td>\n",
       "      <td>app</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B004AFQAUA</td>\n",
       "      <td>AJ9JRKE8AADW0</td>\n",
       "      <td>It's easy to use and transfer songs. If I purc...</td>\n",
       "      <td>Worth the monthly fee</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     productId      reviewerID  \\\n",
       "0   B004A9SDD8  A1N4O8VOJZTDVB   \n",
       "1   B004A9SDD8  A2HQWU6HUKIEC7   \n",
       "2   B004A9SDD8  A1SXASF6GYG96I   \n",
       "3   B004A9SDD8  A2B54P9ZDYH167   \n",
       "4   B004A9SDD8   AFOFZDTX5UC6D   \n",
       "5   B004A9SDD8  A331GYAT4ESYI3   \n",
       "6   B004A9SDD8  A2YEHF8T823TDC   \n",
       "7   B004A9SDD8  A3699WHISXX94Z   \n",
       "8   B004A9SDD8  A2BXV49EIES2TB   \n",
       "9   B004A9SDD8  A37HM5TMCMHJES   \n",
       "10  B004A9SDD8  A1FYZPJLU78R2Y   \n",
       "11  B004A9SDD8   AV58L39SOERMI   \n",
       "12  B004A9SDD8  A31XG60B64OW74   \n",
       "13  B004A9SDD8  A39JZ61LPIVY91   \n",
       "14  B004A9SDD8   AIRKROQMCBVG4   \n",
       "15  B004A9SDD8   AELVL0VXR3VFN   \n",
       "16  B004A9SDD8   A55641MA1CS5F   \n",
       "17  B004AFQAUA  A39TLD5D8M76M4   \n",
       "18  B004AFQAUA  A2XJJKZSEYYW8T   \n",
       "19  B004AFQAUA   AJ9JRKE8AADW0   \n",
       "\n",
       "                                           reviewText  \\\n",
       "0   Loves the song, so he really couldn't wait to ...   \n",
       "1   Oh, how my little grandson loves this app. He'...   \n",
       "2   I found this at a perfect time since my daught...   \n",
       "3   My 1 year old goes back to this game over and ...   \n",
       "4   There are three different versions of the song...   \n",
       "5   THis is just so cute and a great app for littl...   \n",
       "6   I watch my great grandson 4 days a week and it...   \n",
       "7   This app is wild and crazy.  Little ones love ...   \n",
       "8   love love love this app. I was going through d...   \n",
       "9   Very cute, with alot of items to move about.  ...   \n",
       "10  WELL THE CHILDREN LOVE IT AFTER AWHILE YOU GET...   \n",
       "11  I got this app because my 2 year old daughter ...   \n",
       "12  My three year old Plays this game the most he ...   \n",
       "13  Good for little ones, especially if  know the ...   \n",
       "14  My two year old grandson loves this game and p...   \n",
       "15  My granddaughter really loves this. She will l...   \n",
       "16  love it, but wish it was fullscreen on honeyco...   \n",
       "17  does not let you sample only for a sec. if you...   \n",
       "18  this is a very good app and it you need this s...   \n",
       "19  It's easy to use and transfer songs. If I purc...   \n",
       "\n",
       "                                              summary  overall  \n",
       "0                                         Really cute      3.0  \n",
       "1                                 2-year-old loves it      5.0  \n",
       "2                                            Fun game      5.0  \n",
       "3                                We love our Monkeys!      5.0  \n",
       "4   This is my granddaughters favorite app on my K...      5.0  \n",
       "5                                             so cute      5.0  \n",
       "6                                           Terrific!      5.0  \n",
       "7                                 Five Little Monkeys      5.0  \n",
       "8                                   love but to quite      5.0  \n",
       "9                                                Cute      5.0  \n",
       "10                                            MONKEYS      4.0  \n",
       "11                                Could be better....      3.0  \n",
       "12                                Five little monkeys      5.0  \n",
       "13                            Good for small children      3.0  \n",
       "14                                   Fun, fun, fun !!      5.0  \n",
       "15                                            So cute      5.0  \n",
       "16                                            love it      4.0  \n",
       "17                                    dont play there      1.0  \n",
       "18                                                app      5.0  \n",
       "19                              Worth the monthly fee      4.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P97wGoh9DniP"
   },
   "source": [
    "Create a histogram of the scores ('overall') rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "OvY3IiENnZje",
    "outputId": "b2253560-9126-41c1-c55c-ff6c4d492613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x00000001401A1BC8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews.hist('overall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bvw6GK_G_unS"
   },
   "source": [
    "It seems that most reviews are positive. For this exercise, we'll be looking at the task of binary classification. We will bin the reviews into two classes for the purposes of binary sentiment classification -- Like vs Not like. \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zn3vrvHxwxsM"
   },
   "source": [
    "### Create the (class) labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7Hzr4hrCNFl"
   },
   "source": [
    "\n",
    "*  Create a function, create_label that outputs a vector of class labels (Y vector). Reviews with a score strictly greater than *3* should be assigned a positive label (`1`), the label should be, `0` otherwise. \n",
    "*   Apply the function to the *overall* column and assign the result to a new data column in the reviews dataframe, `reviews['Class']`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "p7MxuQ8xDBzc",
    "outputId": "8d4700d7-03a7-430b-b323-8d8b00eb7dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     productId      reviewerID  \\\n",
      "0   B004A9SDD8  A1N4O8VOJZTDVB   \n",
      "1   B004A9SDD8  A2HQWU6HUKIEC7   \n",
      "2   B004A9SDD8  A1SXASF6GYG96I   \n",
      "3   B004A9SDD8  A2B54P9ZDYH167   \n",
      "4   B004A9SDD8   AFOFZDTX5UC6D   \n",
      "5   B004A9SDD8  A331GYAT4ESYI3   \n",
      "6   B004A9SDD8  A2YEHF8T823TDC   \n",
      "7   B004A9SDD8  A3699WHISXX94Z   \n",
      "8   B004A9SDD8  A2BXV49EIES2TB   \n",
      "9   B004A9SDD8  A37HM5TMCMHJES   \n",
      "10  B004A9SDD8  A1FYZPJLU78R2Y   \n",
      "11  B004A9SDD8   AV58L39SOERMI   \n",
      "12  B004A9SDD8  A31XG60B64OW74   \n",
      "13  B004A9SDD8  A39JZ61LPIVY91   \n",
      "14  B004A9SDD8   AIRKROQMCBVG4   \n",
      "15  B004A9SDD8   AELVL0VXR3VFN   \n",
      "16  B004A9SDD8   A55641MA1CS5F   \n",
      "17  B004AFQAUA  A39TLD5D8M76M4   \n",
      "18  B004AFQAUA  A2XJJKZSEYYW8T   \n",
      "19  B004AFQAUA   AJ9JRKE8AADW0   \n",
      "\n",
      "                                           reviewText  \\\n",
      "0   Loves the song, so he really couldn't wait to ...   \n",
      "1   Oh, how my little grandson loves this app. He'...   \n",
      "2   I found this at a perfect time since my daught...   \n",
      "3   My 1 year old goes back to this game over and ...   \n",
      "4   There are three different versions of the song...   \n",
      "5   THis is just so cute and a great app for littl...   \n",
      "6   I watch my great grandson 4 days a week and it...   \n",
      "7   This app is wild and crazy.  Little ones love ...   \n",
      "8   love love love this app. I was going through d...   \n",
      "9   Very cute, with alot of items to move about.  ...   \n",
      "10  WELL THE CHILDREN LOVE IT AFTER AWHILE YOU GET...   \n",
      "11  I got this app because my 2 year old daughter ...   \n",
      "12  My three year old Plays this game the most he ...   \n",
      "13  Good for little ones, especially if  know the ...   \n",
      "14  My two year old grandson loves this game and p...   \n",
      "15  My granddaughter really loves this. She will l...   \n",
      "16  love it, but wish it was fullscreen on honeyco...   \n",
      "17  does not let you sample only for a sec. if you...   \n",
      "18  this is a very good app and it you need this s...   \n",
      "19  It's easy to use and transfer songs. If I purc...   \n",
      "\n",
      "                                              summary  overall  Class  \n",
      "0                                         Really cute      3.0      0  \n",
      "1                                 2-year-old loves it      5.0      1  \n",
      "2                                            Fun game      5.0      1  \n",
      "3                                We love our Monkeys!      5.0      1  \n",
      "4   This is my granddaughters favorite app on my K...      5.0      1  \n",
      "5                                             so cute      5.0      1  \n",
      "6                                           Terrific!      5.0      1  \n",
      "7                                 Five Little Monkeys      5.0      1  \n",
      "8                                   love but to quite      5.0      1  \n",
      "9                                                Cute      5.0      1  \n",
      "10                                            MONKEYS      4.0      1  \n",
      "11                                Could be better....      3.0      0  \n",
      "12                                Five little monkeys      5.0      1  \n",
      "13                            Good for small children      3.0      0  \n",
      "14                                   Fun, fun, fun !!      5.0      1  \n",
      "15                                            So cute      5.0      1  \n",
      "16                                            love it      4.0      1  \n",
      "17                                    dont play there      1.0      0  \n",
      "18                                                app      5.0      1  \n",
      "19                              Worth the monthly fee      4.0      1  \n"
     ]
    }
   ],
   "source": [
    "def create_label(label):\n",
    "    if label >3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "reviews['Class']=reviews['overall'].apply(create_label)\n",
    "\n",
    "print(reviews.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "8ortFsVuf_bP"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "##Solution\n",
    "\n",
    "# Alternate solution:\n",
    "#reviews['Class'] = 1 * (reviews['overall'] > 3)\n",
    "\n",
    "def create_label(x):\n",
    "    if x > 3:\n",
    "        return 1 # 'positive' \n",
    "    return 0 # 'negative'\n",
    "  \n",
    "reviews['Class'] = reviews.overall.apply(create_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PRnEF82anmVC"
   },
   "source": [
    "#### Exercise  \n",
    "* Print the class prior probabilities, P(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M-TTwLreAP9C",
    "outputId": "98f238c2-68fb-4728-8d6e-edefc1ba9d43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723457606678912"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary_priori(class_column):\n",
    "    total_docs=len(class_column)\n",
    "    n_C_1=0\n",
    "    n_C_0=0\n",
    "    for each_class in class_column.values:\n",
    "        if each_class ==0:\n",
    "            n_C_0+=1\n",
    "        else:\n",
    "            n_C_1+=1\n",
    "\n",
    "    p_C_1=n_C_1/total_docs\n",
    "    p_C_0=n_C_0/total_docs\n",
    "\n",
    "    return p_C_1,p_C_0\n",
    "\n",
    "p_C_1,p_C_0 = binary_priori(reviews['Class'])   \n",
    "p_C_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbyB5ulCMw_6"
   },
   "source": [
    "You should see that most (~72% of the labels are positive overall in the dataset). This means we have an issue of class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fAwpW-5wtkM"
   },
   "source": [
    "### Train/Validation/Test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VAecZnucBHTl"
   },
   "source": [
    "Next, lets split the reviews dataframe in to train, validation, and test sets.  Recall that training data is used to train our model.  Validation data is used to develop our model (develop new features, etc...) and tune parameters.  The final result should be reported on the test data (that we haven't looked at throughout). \n",
    "\n",
    "1. Split your data (all instances) into *training* and *testing* (80/20 is a reasonable starting point)\n",
    "2. Split the **training data** into *training* and *validation* (again, 80/20 is a typical split).\n",
    "\n",
    "Note that as the size of the dataset increases, the ratio of train/validation/test may vary in other datasets.  For example, if you have millions (or billions) of instances the splits could be more like 99%/0.5%/0.5% for train/validation/test.  This is because you are still using a large number of instances to evaluate the model.\n",
    "\n",
    "We shuffle the data randomly to avoid potential ordering bias.  Note that because we are all using different random splits of the data every time we run the notebook the results will differ (very) slightly due to differences in the random splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjZlxdgxynj2"
   },
   "outputs": [],
   "source": [
    "# shuffle the data randomly to avoid possible bias.\n",
    "random_reviews = reviews.sample(frac=1)\n",
    "\n",
    "# The min limits the size of the dataset loaded to 100k, 1/8 of the total data. \n",
    "# It's set to not be \"too big\" for this lab. \n",
    "review_limit = min(100000, len(random_reviews))\n",
    "random_reviews = random_reviews.iloc[:review_limit, :]\n",
    "\n",
    "# 1. Split the data 80/20 train/test\n",
    "train_split = int(len(random_reviews) * 0.8)\n",
    "tmp_train = random_reviews.iloc[:train_split,:]\n",
    "test_data = random_reviews.iloc[train_split:,:]\n",
    "\n",
    "# 2. Split the train data into a train/validation split that's 80% train, 20% developemnt \n",
    "validation_split = int(train_split * 0.8)\n",
    "train_data = tmp_train.iloc[:validation_split,:]\n",
    "validation_data = tmp_train.iloc[validation_split:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSpg8jjTBxR-"
   },
   "source": [
    "Lets see some statistics of our resulting datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "iScW8CznIeSb",
    "outputId": "65e23581-fd70-4165-a034-8f3cb3904fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set contains 64000 reviews.\n",
      "Vadlidation set contains 16000 reviews.\n",
      "Test set contains 20000 reviews.\n",
      "Training set contains 72% positive reviews\n",
      "Validation set contains 73% positive reviews\n",
      "Test set contains 73% positive reviews\n"
     ]
    }
   ],
   "source": [
    "print('Training set contains {:d} reviews.'.format(len(train_data)))\n",
    "print('Vadlidation set contains {:d} reviews.'.format(len(validation_data)))\n",
    "print('Test set contains {:d} reviews.'.format(len(test_data)))\n",
    "\n",
    "number_positive_train = sum(train_data['Class'] == 1)\n",
    "number_positive_validation = sum(validation_data['Class'] == 1)\n",
    "number_positive_test = sum(test_data['Class'] == 1)\n",
    "\n",
    "print('Training set contains %0.0f%% positive reviews' % (100*number_positive_train/len(train_data)))\n",
    "print('Validation set contains %0.0f%% positive reviews' % (100*number_positive_validation/len(validation_data)))\n",
    "print('Test set contains %0.0f%% positive reviews' % (100*number_positive_test/len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZT-p3GBM-RY"
   },
   "source": [
    "We can see that the train/dev/test data all have about 72% positive labels.  This is the same percentage as the overall collection. This is a good sanity check to make sure the data is split appropriately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1TDjC_d2Mx9"
   },
   "source": [
    "Now we have our instances with labels.  Now, we need to create a text representation.  We will start by processing the reviews with spaCy to tokenize and normalize the text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aYGX-Vb5dEh-",
    "outputId": "c494e5a3-45bc-46e3-fe39-c67951e5eb50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "spacy version 2.2.3 is\n",
      "OK\n",
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x0000008DC586BC48>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x0000008DC5853E88>)]\n",
      "['tagger', 'parser']\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nnlp = spacy.load('en_core_web_sm', disable=['ner'])\\nnlp.remove_pipe('tagger')\\nnlp.remove_pipe('parser')\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#!python -m spacy download en\n",
    "\n",
    "import spacy\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "# Version checks\n",
    "import importlib\n",
    "def version_check(libname, min_version):\n",
    "    m = importlib.import_module(libname)\n",
    "    print (\"%s version %s is\" % (libname, m.__version__))\n",
    "    print (\"OK\" if m.__version__ >= min_version \n",
    "           else \"out-of-date. Please upgrade!\")\n",
    "    \n",
    "version_check(\"spacy\", \"2.0\")\n",
    "\n",
    "# Load the small english model. \n",
    "# Disable the advanced NLP features in the pipeline for efficiency.\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "print(nlp.pipeline)\n",
    "print(nlp.pipe_names)\n",
    "nlp.remove_pipe('tagger')\n",
    "nlp.remove_pipe('parser')\n",
    "# Verify they are empty.\n",
    "print(nlp.pipeline)\n",
    "\n",
    "\n",
    "'''\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "nlp.remove_pipe('tagger')\n",
    "nlp.remove_pipe('parser')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7-maQNfu8vx"
   },
   "outputs": [],
   "source": [
    "#@Tokenize\n",
    "def spacy_tokenize(string):\n",
    "    tokens = list()\n",
    "    doc = nlp(string)\n",
    "    for token in doc:\n",
    "        tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "#@Normalize\n",
    "def normalize(tokens):\n",
    "    normalized_tokens = list()\n",
    "    for token in tokens:\n",
    "        normalized = token.text.lower().strip()\n",
    "        #print(normalized)\n",
    "        if \"_\" in token.text:\n",
    "            normalized_tokens.append(normalized)\n",
    "        \n",
    "        \n",
    "        if ((token.is_alpha or token.is_digit )):\n",
    "            #if not token.like_url:\n",
    "            normalized_tokens.append(normalized)\n",
    "        \n",
    "    return normalized_tokens\n",
    "    \n",
    "\n",
    "#@Tokenize and normalize\n",
    "def tokenize_normalize(string):\n",
    "    return normalize(spacy_tokenize(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k631u7NTeiES"
   },
   "source": [
    "Test to make sure the normalization is working.  Note that for this simple example we aren't keeping punctuation or emoji.  It might be something that could be useful as an option to test later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_Fjf0ddkcUnx",
    "outputId": "38553aac-d3cd-46dd-b6c6-498b16c2aa0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 't3_mqxoi', 'app', 'is', 'fun', 'very', 'happy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_normalize(\"the t3_mqxoi http://goo45gle.com app is fun. very happy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3_mqxoi\n",
      "t1_c334scx\n",
      "t1_c3354ny\n",
      "t1_c3356y6\n",
      ":D\n",
      ":(\n",
      ":'(\n"
     ]
    }
   ],
   "source": [
    "for t in nlp(\"t3_mqxoi t1_c334scx t1_c3354ny t1_c3356y6 :D :( :'(\"):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dlYo0KmDcZ78"
   },
   "source": [
    "The result should be [the, app, is, fun, very, happy]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haMIuPwxCPXg"
   },
   "source": [
    "Now we are ready to create the features. As this is for text classification, our features are terms. We'll start with a simple one-hot encoding.\n",
    "\n",
    "> Indented block\n",
    "\n",
    "\n",
    "\n",
    "#### Exercise\n",
    "* Create a vectorizer variable, `one_hot_vectorizer`. Use a `CountVectorizer` initialized with `tokenize_normalize` function for the tokenizer parameter. Also use `binary=True` to create a one-hot encoding, set `max_features=20000` to limit the vocabulary to the most frequent 20k words.\n",
    "* Fit the vectorizer model on the `train_data`, the `reviewText` column.\n",
    "* Apply the vectorizer to train on the: `train_data` and be applied on the unseen `validation_data`, and `test_data`. Assign the result to appropriate 'features' variables, `train_features`, `validation_features`, `test_features`\n",
    "\n",
    "**Note**: Running spacy to vectorize all the posts make take several minutes. It is always wise to develop your vectorizers and classifiers on 'small' data before scaling to the full dataset. If it takes more than a couple minutes you should change the dataset size to be smaller (by adjust the 'min' function above to be smaller than 100k).  \n",
    "**Hint**: Recall that `fit` builds a vocabulary. `transform()`and creates a sparse one-hot encoding using the vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FQBMhCbQdAO"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "one_hot_vectorizer=CountVectorizer(tokenizer=tokenize_normalize, binary=True, max_features=20000)\n",
    "\n",
    "train_features=one_hot_vectorizer.fit_transform(train_data['reviewText'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDeHqUfrcbeM"
   },
   "outputs": [],
   "source": [
    "test_features=one_hot_vectorizer.transform(test_data['reviewText'])\n",
    "\n",
    "validation_features=one_hot_vectorizer.transform(validation_data['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-p3_RG6tW3r"
   },
   "source": [
    "### Exercise\n",
    "* Extract the class labels and assign them to convenience variables (see below).\n",
    "* Assign the labels to the corresponding variable, for example labels from `train` should be assigned to `train_labels`. Do the same for `validation_labels` and `test_labels`. \n",
    "* The labels are in `['Class']` column of the corresponding dataframe.\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d97jhRE2tbET"
   },
   "outputs": [],
   "source": [
    "train_labels=train_data['Class']\n",
    "test_labels=test_data['Class']\n",
    "validation_labels=validation_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "5-VUhqH33vI3"
   },
   "outputs": [],
   "source": [
    "#@title Show solution\n",
    "train_labels = train_data['Class']\n",
    "validation_labels = validation_data['Class']\n",
    "test_labels = test_data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWlsGjsdFhDq"
   },
   "source": [
    "Now lets train a classifier using the training data.\n",
    "\n",
    "We will train a [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) classifier. Recall from lecture that the first step for NB is to assume a distribution of the feature data. A \"bernoulli distribution\" is for binary values, whether a value is present or not.  We use the\n",
    "[BernoulliNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) for features with a one-hot encoding.\n",
    "\n",
    "#### Exercise\n",
    "* Import and create a  `BernoulliNB` classifier for the data with default arguments. \n",
    "* `Fit` (train) the classifier model using the `train_features` and `train_labels`\n",
    "* Assign you NB model to `nb_model` variable.\n",
    "\n",
    "**Question:** What would the appropriate Naive Bayes classifier variant be if we used token frequency counts instead of a one-hot encoding?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X7pQh03Li4Pz",
    "outputId": "5b9f4f65-1311-40f1-b46b-55a0b3575cda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB as BNB\n",
    "\n",
    "\n",
    "nb_model=BNB()\n",
    "\n",
    "nb_model.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "JH2aequkgKoP"
   },
   "outputs": [],
   "source": [
    "#@title Show Solution\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB()\n",
    "nb_model = classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDTLXaaULpKo"
   },
   "source": [
    "Can we see how well our classifier is doing? The `score()` function on classifiers calculates the classifier's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YF1P9SCUk76F",
    "outputId": "aca457c5-c0f3-4092-f785-c3bc2f8d2799"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8296875"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.score(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4l3u6PC0lCzZ"
   },
   "source": [
    "On the training data we get a accuracy of around 83% (a bit higher or lower depending on the amount of data and randomness). \n",
    "\n",
    "#### Exercise\n",
    "* Score the trained model on the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tvID85qoDjlc",
    "outputId": "232d3bdb-c84d-422c-ef66-124158f1e840"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8070625"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.score(validation_features,validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwjplrDjEhJJ"
   },
   "source": [
    "It should give you an accuracy of around 81.5%.  It is pretty similar to the training data effectiveness, but slightly lower.  Overall because the two accuracies are similar the model is fit reasonably well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SMbZYmXeEDfE"
   },
   "source": [
    "Now we have our classifier learned, lets try it out on some example reviews. \n",
    "- The `predict()` function just returns the MAP estimate (highest probability class)\n",
    "- The `predict_proba()` returns the normalized probability. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "LKu84e9lvip2",
    "outputId": "7dab83e3-c9f8-4463-9254-2b40f7337ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[[0.37055307 0.62944693]]\n",
      "[1]\n",
      "[[0.00178355 0.99821645]]\n"
     ]
    }
   ],
   "source": [
    "print(nb_model.predict(one_hot_vectorizer.transform([\"the app is awful. total spam.\"])))\n",
    "print(nb_model.predict_proba(one_hot_vectorizer.transform([\"the app is awful. total spam.\"])))\n",
    "\n",
    "print(nb_model.predict(one_hot_vectorizer.transform([\"the app is fun. very happy\"])))\n",
    "print(nb_model.predict_proba(one_hot_vectorizer.transform([\"the app is fun. very happy\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BdZ4WLUETb8"
   },
   "source": [
    "We should expect the  first to be negative, the second positive. However, due to variation in the random subsets of data used (and the limited size, this doesn't always work).  This is why it's important to inspect the model outputs.   \n",
    "\n",
    "* Why might the model perform better on the positive case rather than the negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zs3brY723-RL"
   },
   "source": [
    "Below is a function that prints out a evaluation summary with key metrics as well as a 'classification report'. It also prints out a poorly formatted confusion matrix (see this example for a well labeled version using [plot_confusion_matrix](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5YlrCsgl6pE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def evaluation_summary(description, predictions, true_labels):\n",
    "    print(\"Evaluation for: \" + description)\n",
    "    precision = precision_score(predictions, true_labels, average='macro')\n",
    "    recall = recall_score(predictions, true_labels, average='macro')\n",
    "    accuracy = accuracy_score(predictions, true_labels)\n",
    "    f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
    "    print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
    "    # Specify three digits instead of the default two.\n",
    "    print(classification_report(predictions, true_labels, digits=3))\n",
    "    print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions)) # Note the order here is true, predicted, odd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfX8gUHjooIs"
   },
   "source": [
    "The sklearn.metrics package includes score functions, including the key [classification metrics](https://scikit-learn.org/stable/modules/classes.html#classification-metrics) discussed in lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "ioRqnrK_kSWK",
    "outputId": "a0b523a2-b7bb-45d8-d777-21f8f812b89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for: One-hot NB\n",
      "Classifier 'One-hot NB' has Acc=0.807 P=0.743 R=0.758 F1=0.750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.602     0.660     0.630      3973\n",
      "           1      0.884     0.855     0.870     12027\n",
      "\n",
      "    accuracy                          0.807     16000\n",
      "   macro avg      0.743     0.758     0.750     16000\n",
      "weighted avg      0.814     0.807     0.810     16000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 2624  1738]\n",
      " [ 1349 10289]]\n"
     ]
    }
   ],
   "source": [
    "validation_predicted_labels = nb_model.predict(validation_features)\n",
    "evaluation_summary(\"One-hot NB\",  validation_predicted_labels, validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPFdsZMQwafc"
   },
   "source": [
    "It is important in practice to always have a *baseline* - you need to know that you are better than randomly guessing the class. As discussed in lecture, Sklearn provides instances of [DummyClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) for this purpose.  A dummy classifier has the same interface as all other Estimators (classifiers) in SKLearn.  We `fit` (train) it on the training data and `predict` on the test data.\n",
    "\n",
    "#### Exercise: \n",
    "* Create and train two DummyClassifier instances with `strategy=stratified` (which we sometimes will call 'Random') and `strategy=most_frequent` (MF) which assigns the most common (majority class) label.\n",
    "* Print an evaluation summary of each on the validation data.\n",
    "* Study the output. How do these baselines compare with the one-hot encoding classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "39719WyV3XOO",
    "outputId": "9bbaef82-00c8-4dec-c106-2139496dba86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60255"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf=DummyClassifier(strategy='stratified')\n",
    "\n",
    "dummy_clf.fit(train_features,train_labels)\n",
    "\n",
    "dummy_pred=dummy_clf.predict(train_features)\n",
    "\n",
    "dummy_clf.score(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cpQ--Sqx3Uk"
   },
   "source": [
    "Ok, comparing the results with the dummy classifiers, our classifier's performance can be best described as \"maybe OK\".  The  class prior 'random' classifier gets an accuracy of about 60% and macro F1 of about 0.503.  The majority class has macro F1 of 0.420 and an accuracy 0f 72.5%. \n",
    "\n",
    "The simple majority classifier has an accuracy that's the percentage of the data that is positive. In contrast, the simple classifier that predicts all positives has a lower macro F1 score. F1 is a useful summary measure combining both precision and recall, you will use this in the coursework as well.  Let's see if we can improve the effectiveness.\n",
    "\n",
    "####Exercise: \n",
    "* Now train and evaluate a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier. \n",
    "* Specify a `solver=saga`, a variation of stochastic gradient decent\n",
    "* Evaluate the effectiveness on the validation data using the `evaluation_summary`. \n",
    "\n",
    "*Note:* With the default settings you may get a message, ' ConvergenceWarning: The max_iter was reached which means the coef_ did not converge' If thise happens you should increase the `max_iter` to a higher value than the default (100), try 500. \n",
    "\n",
    "This could take a minute or two to train a LR model on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "gxDNuUZ7nG9v",
    "outputId": "a182661f-1996-415e-97b7-973187d46b92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8562"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "LR_clf=LR(solver='saga',penalty='none')\n",
    "\n",
    "LR_clf.fit(train_features,train_labels)\n",
    "\n",
    "LR_clf.score(test_features,test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhoYBVGirrUy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8plyfRRxE2w"
   },
   "source": [
    "LR should provide a (small) improvement to an accuracy of 85.7% on F1 to approximately 0.814, which is better than a BernoulliNB for this data.\n",
    "\n",
    "Now, let's experiment with different features for LogisticRegression beyond a one-hot encoding of a single column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xk9k3H1tPwCG"
   },
   "source": [
    "## Tuning and Combining Features\n",
    "\n",
    "We want to be able to incorporate features from external sources. SKLearn has multiple ways of doing this. In this lab we will use SKLearn [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "A pipeline is useful because it encampsulates all elements of data processing from input to prediction.  We will use it to pass in a dataset and extract out different fields that we can process and vectorize to create separate features from them. \n",
    "\n",
    "Unfortunately, Pandas does not play nice with SKLearn pipelines natively.  As result, to access multiple columns in s Panda dataframe we need to use a `transformer` to select a column.  We define this for you below. You will use this as one of the steps in your pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnmvvFQgQ7do"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.    \"\"\"\n",
    "\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qIwgDupsZN22"
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "Create a simple pipeline, '`pipe`' that performs vectorization and regression.\n",
    "- Use the `ItemSelector` as the first step in the pipeline. It accepts a pandas data frame and selects a column (to be vectorized in the next step). \n",
    "- The second step should be a CountVectorizer, named, `'cv'` that uses the `tokenizer=tokenize_normalize`. Do not specify any value for `binary`.\n",
    "- The third step should be LogisticRegression, named `'lr'`\n",
    "- Call `fit` on the pipeline to vectorize and train a model. \n",
    "\n",
    "Note: the pipeline performs both vectorization and trains a model in one step. This can be sloowww on large datasets.  Large pipelines are often split up into smaller sub-pipelines (e.g. text preprocessing first) and a model is trained separately.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "gAFgrftLgvmu",
    "outputId": "47059f24-9be7-4415-bf88-f5c68921c2ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('selector', ItemSelector(key='reviewText')),\n",
       "                ('count_vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern=...w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize_normalize at 0x0000000125273048>,\n",
       "                                 vocabulary=None)),\n",
       "                ('Log_reg',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "column_selector=ItemSelector('reviewText')\n",
    "\n",
    "cv=CountVectorizer(tokenizer=tokenize_normalize)\n",
    "\n",
    "lr=LR()\n",
    "\n",
    "params=[('selector',column_selector),('count_vec',cv),('Log_reg',lr)]\n",
    "\n",
    "pipe=Pipeline(params)\n",
    "pipe.fit(train_data,train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VB6P5CqNMSH1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<64000x20000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2028819 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline takes a param which contains all the serial objects with new names, as pipeline accesses individual object prameters with those names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "OgWvHY-HZNNp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('selector', ItemSelector(key='reviewText')),\n",
       "                ('cv',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize_normalize at 0x0000000125273048>,\n",
       "                                 vocabulary=None)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Show code\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('selector', ItemSelector(key='reviewText')),\n",
    "    # Note: This keeps count weights, not one-hot; we'll tune this parameter next.\n",
    "    ('cv', CountVectorizer(tokenizer=tokenize_normalize)),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "pipe.fit(train_data, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evjThY6vgWpd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for: LR Count\n",
      "Classifier 'LR Count' has Acc=0.852 P=0.795 R=0.821 F1=0.806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.669     0.760     0.712      3843\n",
      "           1      0.921     0.881     0.901     12157\n",
      "\n",
      "    accuracy                          0.852     16000\n",
      "   macro avg      0.795     0.821     0.806     16000\n",
      "weighted avg      0.860     0.852     0.855     16000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 2920  1442]\n",
      " [  923 10715]]\n"
     ]
    }
   ],
   "source": [
    "predictions = pipe.predict(validation_data)\n",
    "evaluation_summary(\"LR Count\", predictions, validation_labels)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>overall</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478740</th>\n",
       "      <td>B00AIUUXHC</td>\n",
       "      <td>A1RM8B6R7JRPNI</td>\n",
       "      <td>If I could give this more than 5 stars I would...</td>\n",
       "      <td>Only 5 stars?</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588535</th>\n",
       "      <td>B00CUWWLWG</td>\n",
       "      <td>A2KPPGFMPD20M6</td>\n",
       "      <td>Great fun for a while but now the game won't  ...</td>\n",
       "      <td>Short term game</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10146</th>\n",
       "      <td>B004H6WTJI</td>\n",
       "      <td>A3BVXN5K9PGQ30</td>\n",
       "      <td>This is the best app, ever! Very easy to use. ...</td>\n",
       "      <td>Fabulous!!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32157</th>\n",
       "      <td>B004OZOTSQ</td>\n",
       "      <td>AEEKLHY0XJONG</td>\n",
       "      <td>This is probably one of the most handy apps ou...</td>\n",
       "      <td>SUPER LEGIT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17892</th>\n",
       "      <td>B004JK61K0</td>\n",
       "      <td>A21ZQ92E0V7M52</td>\n",
       "      <td>I really like this email app. I find it much e...</td>\n",
       "      <td>Me Suzie</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712709</th>\n",
       "      <td>B00HAPRVWS</td>\n",
       "      <td>A2X8Q3Y2E08NEF</td>\n",
       "      <td>I downloaded this app for my kids and they lov...</td>\n",
       "      <td>Kids love this app</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302311</th>\n",
       "      <td>B0086700CM</td>\n",
       "      <td>A1FKCUL32I5KC2</td>\n",
       "      <td>Do you have a few seconds to waste while you'r...</td>\n",
       "      <td>Time Waster</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373804</th>\n",
       "      <td>B008XG1X18</td>\n",
       "      <td>A3VCUNJ8OKI106</td>\n",
       "      <td>I was floored by the absolutely unbelievable n...</td>\n",
       "      <td>Great ideas and so many Fantastic Crafters/Coo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222489</th>\n",
       "      <td>B00785P2QC</td>\n",
       "      <td>AG0VYNBGUS7OT</td>\n",
       "      <td>this game is really fun...wish I could play it...</td>\n",
       "      <td>fun game</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356872</th>\n",
       "      <td>B008MOL1HC</td>\n",
       "      <td>AK8EQI7IKMJCO</td>\n",
       "      <td>I bought this app. Then I open it and it says ...</td>\n",
       "      <td>looked good</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64000 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         productId      reviewerID  \\\n",
       "478740  B00AIUUXHC  A1RM8B6R7JRPNI   \n",
       "588535  B00CUWWLWG  A2KPPGFMPD20M6   \n",
       "10146   B004H6WTJI  A3BVXN5K9PGQ30   \n",
       "32157   B004OZOTSQ   AEEKLHY0XJONG   \n",
       "17892   B004JK61K0  A21ZQ92E0V7M52   \n",
       "...            ...             ...   \n",
       "712709  B00HAPRVWS  A2X8Q3Y2E08NEF   \n",
       "302311  B0086700CM  A1FKCUL32I5KC2   \n",
       "373804  B008XG1X18  A3VCUNJ8OKI106   \n",
       "222489  B00785P2QC   AG0VYNBGUS7OT   \n",
       "356872  B008MOL1HC   AK8EQI7IKMJCO   \n",
       "\n",
       "                                               reviewText  \\\n",
       "478740  If I could give this more than 5 stars I would...   \n",
       "588535  Great fun for a while but now the game won't  ...   \n",
       "10146   This is the best app, ever! Very easy to use. ...   \n",
       "32157   This is probably one of the most handy apps ou...   \n",
       "17892   I really like this email app. I find it much e...   \n",
       "...                                                   ...   \n",
       "712709  I downloaded this app for my kids and they lov...   \n",
       "302311  Do you have a few seconds to waste while you'r...   \n",
       "373804  I was floored by the absolutely unbelievable n...   \n",
       "222489  this game is really fun...wish I could play it...   \n",
       "356872  I bought this app. Then I open it and it says ...   \n",
       "\n",
       "                                                  summary  overall  Class  \n",
       "478740                                      Only 5 stars?      5.0      1  \n",
       "588535                                    Short term game      1.0      0  \n",
       "10146                                          Fabulous!!      5.0      1  \n",
       "32157                                         SUPER LEGIT      5.0      1  \n",
       "17892                                            Me Suzie      5.0      1  \n",
       "...                                                   ...      ...    ...  \n",
       "712709                                 Kids love this app      5.0      1  \n",
       "302311                                        Time Waster      5.0      1  \n",
       "373804  Great ideas and so many Fantastic Crafters/Coo...      5.0      1  \n",
       "222489                                           fun game      4.0      1  \n",
       "356872                                        looked good      1.0      0  \n",
       "\n",
       "[64000 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cv',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize_normalize at 0x0000000125273048>,\n",
       "                                 vocabulary=None)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Show code\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    #('selector', ItemSelector(key='reviewText')),\n",
    "    # Note: This keeps count weights, not one-hot; we'll tune this parameter next.\n",
    "    ('cv', CountVectorizer(tokenizer=tokenize_normalize)),\n",
    "    ('lr', LogisticRegression())])\n",
    "pipe.fit(train_data['reviewText'], train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for: LR Count\n",
      "Classifier 'LR Count' has Acc=0.852 P=0.795 R=0.821 F1=0.806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.669     0.760     0.712      3843\n",
      "           1      0.921     0.881     0.901     12157\n",
      "\n",
      "    accuracy                          0.852     16000\n",
      "   macro avg      0.795     0.821     0.806     16000\n",
      "weighted avg      0.860     0.852     0.855     16000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 2920  1442]\n",
      " [  923 10715]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = pipe.predict(validation_data['reviewText'])\n",
    "evaluation_summary(\"LR Count\", predictions, validation_labels)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yj2IZIJEWSdZ"
   },
   "source": [
    "#### Exercise: combining Pipelines + Grid Search\n",
    "* You will tune the parameters of the model / vectorization using Grid search on the train-validation split. \n",
    "* Use `GridSearchCV` to experiment with a one-hot vs bag-of-words model for `CountVectorizer`(`binary=True/False`).\n",
    "* We've provided code to create a `PreDefinedSplit` object below, creating a `split` variable. You will specify `cv=split` to tune effectiveness on the validation set.  \n",
    "* Specify `n_jobs=-1` to us all cores in parallel.\n",
    "* Specify the `scoring='f1_macro'` parameter (instead of the default accuracy).\n",
    "* `Fit` the GridSearchCV object on the `combined_train_validation_data` with labels `combined_train_validation_labels` provided below. \n",
    "\n",
    "The result will print the best set of parameters.  You can then specify these parameters in your LR model to apply on the test data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hf_yaZstxKeW"
   },
   "source": [
    "#### Code to create pre-defined splits that GridSearch can use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "saD_QFbBteDN",
    "outputId": "017658c7-c700-4858-b250-bb885bb5e4c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ...  0  0  0]\n",
      "[1 0 1 ... 1 1 0]\n",
      "TRAIN: [    0     1     2 ... 63997 63998 63999] TEST: [64000 64001 64002 ... 79997 79998 79999]\n",
      "64000   16000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "# Combine the train an validation back together for parameter tuning with GridSearchCV\n",
    "# There's no way to pass them in separately, which is a pain.\n",
    "combined_train_validation_data = pd.concat((train_data, validation_data))\n",
    "combined_train_validation_labels = np.concatenate((train_labels, validation_labels), axis=0)\n",
    "\n",
    "\n",
    "# Create the splits with an index mask. \n",
    "# Train data indices get a -1, validation data indices get a 0.\n",
    "train_array = np.full(len(train_data), -1, dtype=int)\n",
    "validation_array = np.zeros(len(validation_data), dtype=int)\n",
    "\n",
    "# Create the final mask.\n",
    "train_validation_fold = np.concatenate( (train_array, validation_array),axis=0)\n",
    "print(train_validation_fold)\n",
    "print(combined_train_validation_labels)\n",
    "\n",
    "# Create the split from the index mask\n",
    "split = PredefinedSplit(test_fold=train_validation_fold)\n",
    "\n",
    "# View the train/test split to verify it.\n",
    "for train_index, test_index in split.split():\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(len(train_index),\" \",len(test_index))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80000,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(combined_train_validation_data.shape)\n",
    "combined_train_validation_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsN8_4P9uC1X"
   },
   "source": [
    "Fill in the skeleton below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>overall</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478740</th>\n",
       "      <td>B00AIUUXHC</td>\n",
       "      <td>A1RM8B6R7JRPNI</td>\n",
       "      <td>If I could give this more than 5 stars I would...</td>\n",
       "      <td>Only 5 stars?</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588535</th>\n",
       "      <td>B00CUWWLWG</td>\n",
       "      <td>A2KPPGFMPD20M6</td>\n",
       "      <td>Great fun for a while but now the game won't  ...</td>\n",
       "      <td>Short term game</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10146</th>\n",
       "      <td>B004H6WTJI</td>\n",
       "      <td>A3BVXN5K9PGQ30</td>\n",
       "      <td>This is the best app, ever! Very easy to use. ...</td>\n",
       "      <td>Fabulous!!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32157</th>\n",
       "      <td>B004OZOTSQ</td>\n",
       "      <td>AEEKLHY0XJONG</td>\n",
       "      <td>This is probably one of the most handy apps ou...</td>\n",
       "      <td>SUPER LEGIT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17892</th>\n",
       "      <td>B004JK61K0</td>\n",
       "      <td>A21ZQ92E0V7M52</td>\n",
       "      <td>I really like this email app. I find it much e...</td>\n",
       "      <td>Me Suzie</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191334</th>\n",
       "      <td>B006P1UR60</td>\n",
       "      <td>AJSBTMO40E0FK</td>\n",
       "      <td>It is OK, I was hoping for a little more ease ...</td>\n",
       "      <td>Maps</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528731</th>\n",
       "      <td>B00BHHIWQO</td>\n",
       "      <td>A1Y6GXJHJMUQDO</td>\n",
       "      <td>Love this app, it's very fun. I highly recomme...</td>\n",
       "      <td>great app</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145117</th>\n",
       "      <td>B0064X7B4A</td>\n",
       "      <td>A35E66J3CQ6LYZ</td>\n",
       "      <td>for all you facebook gamers now you can play w...</td>\n",
       "      <td>great game</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395638</th>\n",
       "      <td>B0096TZFEM</td>\n",
       "      <td>A1QWCGDJ3H7EGV</td>\n",
       "      <td>this games seemed corny at first, but after yo...</td>\n",
       "      <td>Fish vs Pirates</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416396</th>\n",
       "      <td>B009HQ9UHC</td>\n",
       "      <td>A12F1OPZ17YHBS</td>\n",
       "      <td>I haven't actually played this game so I'm not...</td>\n",
       "      <td>I dont know</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         productId      reviewerID  \\\n",
       "478740  B00AIUUXHC  A1RM8B6R7JRPNI   \n",
       "588535  B00CUWWLWG  A2KPPGFMPD20M6   \n",
       "10146   B004H6WTJI  A3BVXN5K9PGQ30   \n",
       "32157   B004OZOTSQ   AEEKLHY0XJONG   \n",
       "17892   B004JK61K0  A21ZQ92E0V7M52   \n",
       "...            ...             ...   \n",
       "191334  B006P1UR60   AJSBTMO40E0FK   \n",
       "528731  B00BHHIWQO  A1Y6GXJHJMUQDO   \n",
       "145117  B0064X7B4A  A35E66J3CQ6LYZ   \n",
       "395638  B0096TZFEM  A1QWCGDJ3H7EGV   \n",
       "416396  B009HQ9UHC  A12F1OPZ17YHBS   \n",
       "\n",
       "                                               reviewText          summary  \\\n",
       "478740  If I could give this more than 5 stars I would...    Only 5 stars?   \n",
       "588535  Great fun for a while but now the game won't  ...  Short term game   \n",
       "10146   This is the best app, ever! Very easy to use. ...       Fabulous!!   \n",
       "32157   This is probably one of the most handy apps ou...      SUPER LEGIT   \n",
       "17892   I really like this email app. I find it much e...         Me Suzie   \n",
       "...                                                   ...              ...   \n",
       "191334  It is OK, I was hoping for a little more ease ...             Maps   \n",
       "528731  Love this app, it's very fun. I highly recomme...        great app   \n",
       "145117  for all you facebook gamers now you can play w...       great game   \n",
       "395638  this games seemed corny at first, but after yo...  Fish vs Pirates   \n",
       "416396  I haven't actually played this game so I'm not...      I dont know   \n",
       "\n",
       "        overall  Class  \n",
       "478740      5.0      1  \n",
       "588535      1.0      0  \n",
       "10146       5.0      1  \n",
       "32157       5.0      1  \n",
       "17892       5.0      1  \n",
       "...         ...    ...  \n",
       "191334      3.0      0  \n",
       "528731      4.0      1  \n",
       "145117      5.0      1  \n",
       "395638      5.0      1  \n",
       "416396      3.0      0  \n",
       "\n",
       "[80000 rows x 6 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1FL7f0ukjJ3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['cv', 'lr']\n",
      "parameters:\n",
      "{'cv__binary': (True, False), 'lr__C': [0.001, 0.01, 0.1, 1]}\n",
      "(80000, 6)\n",
      "(80000,)\n",
      "Fitting 1 folds for each of 8 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.808\n",
      "Best parameters set:\n",
      "\tcv__binary: False\n",
      "\tlr__C: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Specify parameters to tune\n",
    "# Use names from the pipeline and argument names separated with: \"___\" string. \n",
    "# e.g. 'lr__max_iter': (100, 500) to search two values 100,500 for the \"max_iter\" parameter\n",
    "# for the logistic regression.\n",
    "\n",
    "# Parameters to tune.\n",
    "params = {\n",
    "    # Fill in the parameter for CountVectorizer with the binary parameter.\n",
    "   'cv__binary': (True,False),\n",
    "    'lr__C':[0.001,.01,0.1,1],\n",
    "    #'cv__sublinear_tf':(True,False)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "pipe_new = Pipeline([\n",
    "    ('selector', ItemSelector(key='reviewText')),\n",
    "    # Note: This keeps count weights, not one-hot; we'll tune this parameter next.\n",
    "    ('cv', CountVectorizer(tokenizer=tokenize_normalize)),\n",
    "    ('lr', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pass in your pipeline, params (to tune), scoring, and split parameters here!\n",
    "grid_search = GridSearchCV(estimator=pipe_new,param_grid=params, n_jobs=-1, scoring='f1_macro', verbose=1, cv=split )\n",
    "print(\"Performing grid search...\")\n",
    "\n",
    "prediction_pipeline=pipe\n",
    "\n",
    "print(\"pipeline:\", [name for name, _ in prediction_pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(params)\n",
    "\n",
    "# FILL IN HERE -- Fit grid_search on the combined train/validation data and labels.\n",
    "\n",
    "print(combined_train_validation_data.shape)\n",
    "print(combined_train_validation_labels.shape)\n",
    "\n",
    "grid_search.fit(combined_train_validation_data,combined_train_validation_labels)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('selector', ItemSelector(key='reviewText')),\n",
       "  ('cv',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=<function tokenize_normalize at 0x0000000125273048>,\n",
       "                   vocabulary=None)),\n",
       "  ('lr',\n",
       "   LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                      multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                      warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'selector': ItemSelector(key='reviewText'),\n",
       " 'cv': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=<function tokenize_normalize at 0x0000000125273048>,\n",
       "                 vocabulary=None),\n",
       " 'lr': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'selector__key': 'reviewText',\n",
       " 'cv__analyzer': 'word',\n",
       " 'cv__binary': False,\n",
       " 'cv__decode_error': 'strict',\n",
       " 'cv__dtype': numpy.int64,\n",
       " 'cv__encoding': 'utf-8',\n",
       " 'cv__input': 'content',\n",
       " 'cv__lowercase': True,\n",
       " 'cv__max_df': 1.0,\n",
       " 'cv__max_features': None,\n",
       " 'cv__min_df': 1,\n",
       " 'cv__ngram_range': (1, 1),\n",
       " 'cv__preprocessor': None,\n",
       " 'cv__stop_words': None,\n",
       " 'cv__strip_accents': None,\n",
       " 'cv__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cv__tokenizer': <function __main__.tokenize_normalize(string)>,\n",
       " 'cv__vocabulary': None,\n",
       " 'lr__C': 0.1,\n",
       " 'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__fit_intercept': True,\n",
       " 'lr__intercept_scaling': 1,\n",
       " 'lr__l1_ratio': None,\n",
       " 'lr__max_iter': 100,\n",
       " 'lr__multi_class': 'auto',\n",
       " 'lr__n_jobs': None,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': None,\n",
       " 'lr__solver': 'lbfgs',\n",
       " 'lr__tol': 0.0001,\n",
       " 'lr__verbose': 0,\n",
       " 'lr__warm_start': False}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_params()['cv__binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_params()['lr__C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6L-2xtfkp0Z"
   },
   "source": [
    "You should find that using counts doesn't help this classification task.  Let's move one to something that does. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFzOBxMYQ9Bv"
   },
   "source": [
    "#### Exercise\n",
    "In this exercise you'll combine features from multiple data frame fields using a [FeatureUnion](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html). \n",
    "\n",
    "If this is a bit confusing it's because FeatureUnions are a bit complicated. If you get stuck, please look at the solution and understand it. \n",
    "\n",
    "There's a nice post on how to be a [Kaggle Pro using FeatureUnion and Pipelines](https://www.kaggle.com/metadist/work-like-a-pro-with-pipelines-and-feature-unions) with a few good examples. Once you complete this you'll be on your way to being a 'Pro'.\n",
    "\n",
    "* Create a Pipeline, `pipeline_feature_union`.  \n",
    "* At first step in the pipeline create `FeatureUnion`. Inside of the `FeatureUnion`, (for each field) create a sub-pipeline that will be in an array and passed as an argument.  \n",
    "* Each sub-pipeline should contain a `ItemSelector` to select the field, then a vectorization step with the `CountVectorizer` that creates a one-hot encoding for it. \n",
    "* The second step (outside the union) is a LogisticRegression model.\n",
    "* Apply fit on pipeline with the `train_data` and `train_labels` to vectorize and train the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2892W2VLUuQB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "1pSXnmNWC_q2",
    "outputId": "1e637cdf-0dec-4ee9-cfcb-a6d92b2b5086"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('union',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('text',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  ItemSelector(key='reviewText')),\n",
       "                                                                 ('one-hot',\n",
       "                                                                  CountVectorizer(analyzer='word',\n",
       "                                                                                  binary=True,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.int64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=True,\n",
       "                                                                                  max_df=1.0,\n",
       "                                                                                  max_features=None,\n",
       "                                                                                  min_df=1,...\n",
       "                                                                                  tokenizer=<function tokenize_normalize at 0x000000016D232C18>,\n",
       "                                                                                  vocabulary=None))],\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Show code\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Use FeatureUnion to combine the features from text and summary\n",
    "pipeline_feature_union = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "          [\n",
    "            ('text', Pipeline([\n",
    "                \n",
    "              ('selector', ItemSelector(key='reviewText')),\n",
    "              ('one-hot', CountVectorizer(tokenizer=tokenize_normalize, binary=True)), \n",
    "              ])),\n",
    "            ('summary', Pipeline([\n",
    "              ('selector', ItemSelector(key='summary')),\n",
    "              ('one-hot', CountVectorizer(tokenizer=tokenize_normalize, binary=True)), \n",
    "              ])),\n",
    "        ])\n",
    "        ),\n",
    "        ('lr', LogisticRegression())\n",
    "    ])\n",
    "pipeline_feature_union.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yidLvBXPieZa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for: LR Union Pipeline\n",
      "Classifier 'LR Union Pipeline' has Acc=0.884 P=0.842 R=0.860 F1=0.850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.750     0.811     0.779      4036\n",
      "           1      0.934     0.909     0.921     11964\n",
      "\n",
      "    accuracy                          0.884     16000\n",
      "   macro avg      0.842     0.860     0.850     16000\n",
      "weighted avg      0.888     0.884     0.886     16000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 3272  1090]\n",
      " [  764 10874]]\n"
     ]
    }
   ],
   "source": [
    "evaluation_summary(\"LR Union Pipeline\", pipeline_feature_union.predict(validation_data), validation_labels)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GT6SvAOCVb-p"
   },
   "source": [
    "This provides a significant boost in effectiveness up to 88.6% accuracy and about 0.854 F1.  Having richer features helps!  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TAD 2020 Lab 4 App Reviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
